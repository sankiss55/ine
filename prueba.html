<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>IA Segmentaci√≥n ONNX - Visualizador</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #0f172a; color: white; display: flex; flex-direction: column; align-items: center; padding: 20px; }
        .card { background: #1e293b; padding: 2rem; border-radius: 15px; text-align: center; max-width: 700px; width: 100%; }
        .image-stack { position: relative; width: 640px; height: 640px; margin: 20px auto; border: 2px solid #38bdf8; border-radius: 8px; background: #000; overflow: hidden; }
        .stack-layer { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        #overlay-canvas { pointer-events: none; mix-blend-mode: screen; }
        .btn { background: #38bdf8; color: #0f172a; padding: 12px 24px; border-radius: 8px; cursor: pointer; font-weight: bold; display: inline-block; }
        #status { margin-top: 15px; font-weight: bold; color: #4ade80; }
        .hidden { display: none; }
    </style>
</head>
<body>

<div class="card">
    <h1>Detector de Segmentaci√≥n (INE)</h1>
    <label class="btn">
        Subir Imagen de Prueba
        <input type="file" id="fileInput" accept="image/*" style="display:none">
    </label>
    <p id="status">Cargando modelo de segmentaci√≥n...</p>

    <div class="image-stack">
        <img id="preview-image" class="stack-layer">
        <canvas id="overlay-canvas" class="stack-layer"></canvas>
    </div>
</div>

<canvas id="process-canvas" class="hidden"></canvas>

<script>
    const WIDTH = 640;
    const HEIGHT = 640;
    const MODEL_PATH = './modelo.onnx'; 
    let session;

    async function init() {
        try {
            // Se recomienda usar WASM para mayor compatibilidad en modelos de segmentaci√≥n
            session = await ort.InferenceSession.create(MODEL_PATH, { executionProviders: ['wasm'] });
            document.getElementById('status').innerText = "‚úÖ IA Lista. Sube una imagen.";
        } catch (e) {
            alert("Error al cargar modelo: " + e.message);
        }
    }

    document.getElementById('fileInput').onchange = function(e) {
        const file = e.target.files[0];
        if (!file) return;
        
        const reader = new FileReader();
        reader.onload = function(event) {
            const img = document.getElementById('preview-image');
            img.src = event.target.result;
            img.onload = () => {
                 document.getElementById('overlay-canvas').width = WIDTH;
                 document.getElementById('overlay-canvas').height = HEIGHT;
                 procesarSegmentacion(img);
            };
        };
        reader.readAsDataURL(file);
    };

    async function procesarSegmentacion(imgElement) {
        const status = document.getElementById('status');
        status.innerText = "üß† Segmentando...";

        const procCanvas = document.getElementById('process-canvas');
        procCanvas.width = WIDTH;
        procCanvas.height = HEIGHT;
        const ctx = procCanvas.getContext('2d');
        ctx.drawImage(imgElement, 0, 0, WIDTH, HEIGHT);

        const imageData = ctx.getImageData(0, 0, WIDTH, HEIGHT).data;
        const inputData = new Float32Array(WIDTH * HEIGHT * 3);
        
        // Preprocesamiento: CHW format (Channel, Height, Width)
        for (let i = 0, j = 0; i < imageData.length; i += 4) {
            inputData[j] = imageData[i] / 255.0;
            inputData[j + WIDTH * HEIGHT] = imageData[i+1] / 255.0;
            inputData[j + 2 * WIDTH * HEIGHT] = imageData[i+2] / 255.0;
            j++;
        }

        try {
            const tensor = new ort.Tensor('float32', inputData, [1, 3, HEIGHT, WIDTH]);
            // Nota: Cambia 'images' por el nombre de entrada de tu modelo si es necesario
            const results = await session.run({ images: tensor });
            
            // En modelos de segmentaci√≥n, la salida suele ser el tensor con mayor tama√±o
            // Buscamos autom√°ticamente la salida que contenga la m√°scara
            const outputKey = Object.keys(results).find(key => results[key].data.length > 1000) || Object.keys(results)[0];
            const outputData = results[outputKey].data;

            dibujarMascara(outputData);
            status.innerText = "‚úÖ √Årea captada visualizada.";

        } catch (err) {
            alert("Error en el modelo: " + err.message);
            status.innerText = "‚ùå Error en inferencia.";
        }
    }

    function dibujarMascara(data) {
        const canvas = document.getElementById('overlay-canvas');
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0,0, WIDTH, HEIGHT);

        const imgOut = ctx.createImageData(WIDTH, HEIGHT);
        const rgba = imgOut.data;

        // L√≥gica de visualizaci√≥n de segmentaci√≥n:
        // Si el valor en el tensor es positivo/alto, significa que ese p√≠xel pertenece al objeto
        for (let i = 0; i < WIDTH * HEIGHT; i++) {
            const val = data[i]; 
            const pixelIndex = i * 4;

            // Si el valor es mayor a un umbral (0.5), pintamos de color Cian ne√≥n
            if (val > 0.5) {
                rgba[pixelIndex + 0] = 56;  // R
                rgba[pixelIndex + 1] = 189; // G
                rgba[pixelIndex + 2] = 248; // B
                rgba[pixelIndex + 3] = 160; // Opacidad (Alpha)
            } else {
                rgba[pixelIndex + 3] = 0;   // Transparente
            }
        }
        ctx.putImageData(imgOut, 0, 0);
    }

    init();
</script>
</body>
</html>
