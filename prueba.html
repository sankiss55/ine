<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Visualizador Segmentaci√≥n YOLOv8</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { font-family: sans-serif; background: #0f172a; color: white; display: flex; flex-direction: column; align-items: center; padding: 20px; }
        .card { background: #1e293b; padding: 20px; border-radius: 15px; text-align: center; max-width: 640px; }
        .image-container { position: relative; width: 640px; height: 640px; background: #000; margin-top: 20px; border: 2px solid #38bdf8; }
        #preview, #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        #overlay { pointer-events: none; opacity: 0.7; }
        .btn { background: #38bdf8; color: #0f172a; padding: 10px 20px; border-radius: 8px; cursor: pointer; font-weight: bold; }
    </style>
</head>
<body>

<div class="card">
    <h1>Detector INE (Segmentaci√≥n)</h1>
    <label class="btn">
        Seleccionar Imagen
        <input type="file" id="fileInput" accept="image/*" style="display:none">
    </label>
    <p id="status">Cargando modelo...</p>

    <div class="image-container">
        <img id="preview">
        <canvas id="overlay"></canvas>
    </div>
</div>

<script>
    const WIDTH = 640;
    const HEIGHT = 640;
    let session;

    async function init() {
        try {
            // Usamos WASM para mayor estabilidad con modelos de segmentaci√≥n
            session = await ort.InferenceSession.create('./best.onnx', { executionProviders: ['wasm'] });
            document.getElementById('status').innerText = "‚úÖ Modelo ONNX Cargado";
        } catch (e) {
            document.getElementById('status').innerText = "‚ùå Error: " + e.message;
        }
    }

    document.getElementById('fileInput').onchange = (e) => {
        const file = e.target.files[0];
        if (!file) return;
        const reader = new FileReader();
        reader.onload = (ev) => {
            const img = document.getElementById('preview');
            img.src = ev.target.result;
            img.onload = () => procesar(img);
        };
        reader.readAsDataURL(file);
    };

    async function procesar(imgElement) {
        const status = document.getElementById('status');
        status.innerText = "üß† Analizando...";

        // 1. Crear canvas temporal para redimensionar a 640x640
        const canvas = document.createElement('canvas');
        canvas.width = WIDTH;
        canvas.height = HEIGHT;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(imgElement, 0, 0, WIDTH, HEIGHT);
        const imageData = ctx.getImageData(0, 0, WIDTH, HEIGHT).data;

        // 2. Formato BCHW (1, 3, 640, 640)
        const input = new Float32Array(WIDTH * HEIGHT * 3);
        for (let i = 0, j = 0; i < imageData.length; i += 4) {
            input[j] = imageData[i] / 255.0;
            input[j + WIDTH * HEIGHT] = imageData[i+1] / 255.0;
            input[j + 2 * WIDTH * HEIGHT] = imageData[i+2] / 255.0;
            j++;
        }

        try {
            const tensor = new ort.Tensor('float32', input, [1, 3, HEIGHT, WIDTH]);
            const results = await session.run({ images: tensor });

            // 3. Capturar la salida de prototipos (la de 160x160)
            // Seg√∫n tu log, es la que tiene 32 * 160 * 160 = 819,200 valores (o similar)
            const outputNames = Object.keys(results);
            // Buscamos el tensor que tiene la forma de m√°scara (normalmente el segundo)
            const maskData = results[outputNames[1]].data; 

            dibujarMascara(maskData);
            status.innerText = "‚úÖ INE Detectada";
        } catch (err) {
            status.innerText = "‚ùå Error en inferencia";
            console.error(err);
        }
    }

    function dibujarMascara(maskData) {
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');
        canvas.width = WIDTH;
        canvas.height = HEIGHT;
        ctx.clearRect(0, 0, WIDTH, HEIGHT);

        const imgOut = ctx.createImageData(160, 160); // Tama√±o del prototipo
        
        // Vamos a promediar las 32 capas de prototipos para ver la "activaci√≥n"
        for (let i = 0; i < 160 * 160; i++) {
            let val = 0;
            // Sumamos la activaci√≥n de los primeros prototipos
            for(let j = 0; j < 32; j++) {
                val += maskData[i + (j * 160 * 160)];
            }
            val = val / 32; // Promedio

            const p = i * 4;
            if (val > 0.1) { // Umbral de sensibilidad
                imgOut.data[p + 0] = 0;   // R
                imgOut.data[p + 1] = 255; // G
                imgOut.data[p + 2] = 255; // B (Cian)
                imgOut.data[p + 3] = 180; // Opacidad
            }
        }

        // Dibujamos la m√°scara peque√±a y el navegador la estira a 640x640 autom√°ticamente
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = 160;
        tempCanvas.height = 160;
        tempCanvas.getContext('2d').putImageData(imgOut, 0, 0);
        
        ctx.imageSmoothingEnabled = true;
        ctx.drawImage(tempCanvas, 0, 0, WIDTH, HEIGHT);
    }

    init();
</script>
</body>
</html>
