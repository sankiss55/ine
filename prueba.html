<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Real-Time INE Scanner</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #0f172a; color: white; display: flex; flex-direction: column; align-items: center; margin: 0; padding: 20px; }
        .container { position: relative; width: 640px; height: 480px; border-radius: 20px; overflow: hidden; border: 4px solid #38bdf8; box-shadow: 0 0 20px rgba(56, 189, 248, 0.3); }
        #video, #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        #overlay { pointer-events: none; z-index: 10; }
        .status-bar { background: #1e293b; padding: 15px 30px; border-radius: 50px; margin-bottom: 20px; font-weight: bold; border: 1px solid #334155; }
        .guide-box { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 80%; height: 60%; border: 2px dashed rgba(255,255,255,0.5); border-radius: 15px; pointer-events: none; z-index: 5; }
    </style>
</head>
<body>

    <div class="status-bar" id="status">Iniciando C√°mara...</div>

    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
        <div class="guide-box"></div>
    </div>

<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const status = document.getElementById('status');
    
    let session;
    const WIDTH = 640;
    const HEIGHT = 640;

    async function setupWebcam() {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { facingMode: "environment", width: 640, height: 480 }, 
            audio: false 
        });
        video.srcObject = stream;
        return new Promise((resolve) => video.onloadedmetadata = resolve);
    }

    async function init() {
        try {
            // Se recomienda usar el modelo cuantizado (.onnx) para que corra fluido en web
            session = await ort.InferenceSession.create('./best.onnx', { 
                executionProviders: ['wasm'], // 'webgl' es m√°s r√°pido pero a veces inestable con segmentaci√≥n
                graphOptimizationLevel: 'all' 
            });
            status.innerText = "üöÄ IA Lista: Coloca el INE frente a la c√°mara";
            status.style.color = "#38bdf8";
            
            await setupWebcam();
            predict(); // Iniciar bucle
        } catch (e) {
            status.innerText = "‚ùå Error: " + e.message;
        }
    }

    async function predict() {
        // 1. Dibujar frame actual en un canvas oculto para pre-procesamiento
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = WIDTH;
        tempCanvas.height = HEIGHT;
        const tempCtx = tempCanvas.getContext('2d');
        tempCtx.drawImage(video, 0, 0, WIDTH, HEIGHT);
        
        const imageData = tempCtx.getImageData(0, 0, WIDTH, HEIGHT).data;
        const input = new Float32Array(WIDTH * HEIGHT * 3);

        // 2. Pre-procesamiento (Normalizaci√≥n y transposici√≥n a NCHW)
        for (let i = 0, j = 0; i < imageData.length; i += 4) {
            input[j] = imageData[i] / 255.0;
            input[j + WIDTH * HEIGHT] = imageData[i+1] / 255.0;
            input[j + 2 * WIDTH * HEIGHT] = imageData[i+2] / 255.0;
            j++;
        }

        const tensor = new ort.Tensor('float32', input, [1, 3, HEIGHT, WIDTH]);
        
        try {
            const results = await session.run({ images: tensor });
            const outputNames = Object.keys(results);
            
            // Ajusta el √≠ndice seg√∫n tu modelo (usualmente el tensor de m√°scaras es el de mayor tama√±o)
            const maskData = results[outputNames[1]].data; 
            renderMask(maskData);
            
        } catch (e) {
            console.error(e);
        }

        // 3. Siguiente frame
        requestAnimationFrame(predict);
    }

    function renderMask(maskData) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Crear m√°scara visual
        const maskCanvas = document.createElement('canvas');
        maskCanvas.width = 160;
        maskCanvas.height = 160;
        const mCtx = maskCanvas.getContext('2d');
        const imgOut = mCtx.createImageData(160, 160);

        for (let i = 0; i < 160 * 160; i++) {
            let val = 0;
            for(let j = 0; j < 32; j++) val += maskData[i + (j * 160 * 160)];
            val = val / 32;

            const p = i * 4;
            if (val > 0.5) { // Ajusta el umbral (Threshold)
                imgOut.data[p + 0] = 56;  // R
                imgOut.data[p + 1] = 189; // G
                imgOut.data[p + 2] = 248; // B
                imgOut.data[p + 3] = 150; // Alpha
            }
        }
        
        mCtx.putImageData(imgOut, 0, 0);
        
        // Estirar la m√°scara al tama√±o real del video
        ctx.globalAlpha = 0.6;
        ctx.drawImage(maskCanvas, 0, 0, canvas.width, canvas.height);
    }

    init();
</script>
</body>
</html>
    async function init() {
        try {
            // Usamos WASM para mayor estabilidad con modelos de segmentaci√≥n
            session = await ort.InferenceSession.create('./best.onnx', { executionProviders: ['wasm'] });
            document.getElementById('status').innerText = "‚úÖ Modelo ONNX Cargado";
        } catch (e) {
            document.getElementById('status').innerText = "‚ùå Error: " + e.message;
        }
    }

    document.getElementById('fileInput').onchange = (e) => {
        const file = e.target.files[0];
        if (!file) return;
        const reader = new FileReader();
        reader.onload = (ev) => {
            const img = document.getElementById('preview');
            img.src = ev.target.result;
            img.onload = () => procesar(img);
        };
        reader.readAsDataURL(file);
    };

    async function procesar(imgElement) {
        const status = document.getElementById('status');
        status.innerText = "üß† Analizando...";

        // 1. Crear canvas temporal para redimensionar a 640x640
        const canvas = document.createElement('canvas');
        canvas.width = WIDTH;
        canvas.height = HEIGHT;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(imgElement, 0, 0, WIDTH, HEIGHT);
        const imageData = ctx.getImageData(0, 0, WIDTH, HEIGHT).data;

        // 2. Formato BCHW (1, 3, 640, 640)
        const input = new Float32Array(WIDTH * HEIGHT * 3);
        for (let i = 0, j = 0; i < imageData.length; i += 4) {
            input[j] = imageData[i] / 255.0;
            input[j + WIDTH * HEIGHT] = imageData[i+1] / 255.0;
            input[j + 2 * WIDTH * HEIGHT] = imageData[i+2] / 255.0;
            j++;
        }

        try {
            const tensor = new ort.Tensor('float32', input, [1, 3, HEIGHT, WIDTH]);
            const results = await session.run({ images: tensor });

            // 3. Capturar la salida de prototipos (la de 160x160)
            // Seg√∫n tu log, es la que tiene 32 * 160 * 160 = 819,200 valores (o similar)
            const outputNames = Object.keys(results);
            // Buscamos el tensor que tiene la forma de m√°scara (normalmente el segundo)
            const maskData = results[outputNames[1]].data; 

            dibujarMascara(maskData);
            status.innerText = "‚úÖ INE Detectada";
        } catch (err) {
            status.innerText = "‚ùå Error en inferencia";
            console.error(err);
        }
    }

    function dibujarMascara(maskData) {
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');
        canvas.width = WIDTH;
        canvas.height = HEIGHT;
        ctx.clearRect(0, 0, WIDTH, HEIGHT);

        const imgOut = ctx.createImageData(160, 160); // Tama√±o del prototipo
        
        // Vamos a promediar las 32 capas de prototipos para ver la "activaci√≥n"
        for (let i = 0; i < 160 * 160; i++) {
            let val = 0;
            // Sumamos la activaci√≥n de los primeros prototipos
            for(let j = 0; j < 32; j++) {
                val += maskData[i + (j * 160 * 160)];
            }
            val = val / 32; // Promedio

            const p = i * 4;
            if (val > 0.8) { // Umbral de sensibilidad
                imgOut.data[p + 0] = 0;   // R
                imgOut.data[p + 1] = 255; // G
                imgOut.data[p + 2] = 255; // B (Cian)
                imgOut.data[p + 3] = 180; // Opacidad
            }
        }

        // Dibujamos la m√°scara peque√±a y el navegador la estira a 640x640 autom√°ticamente
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = 160;
        tempCanvas.height = 160;
        tempCanvas.getContext('2d').putImageData(imgOut, 0, 0);
        
        ctx.imageSmoothingEnabled = true;
        ctx.drawImage(tempCanvas, 0, 0, WIDTH, HEIGHT);
    }

    init();
</script>
</body>
</html>
